{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26cf0bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import wandb\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "from attentionGAN import AttentionGAN\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "from visualizer import Visualizer\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e4c1c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor2im(input_image, imtype=np.uint8):\n",
    "    \"\"\"\"Converts a Tensor array into a numpy image array.\n",
    "\n",
    "    Parameters:\n",
    "        input_image (tensor) --  the input image tensor array\n",
    "        imtype (type)        --  the desired type of the converted numpy array\n",
    "    \"\"\"\n",
    "    if not isinstance(input_image, np.ndarray):\n",
    "        if isinstance(input_image, torch.Tensor):  # get the data from a variable\n",
    "            image_tensor = input_image.data\n",
    "        else:\n",
    "            return input_image\n",
    "        image_numpy = image_tensor[0].clamp(-1.0, 1.0).cpu().float().numpy()  # convert it into a numpy array\n",
    "        if image_numpy.shape[0] == 1:  # grayscale to RGB\n",
    "            image_numpy = np.tile(image_numpy, (3, 1, 1))\n",
    "        image_numpy = (np.transpose(image_numpy, (1, 2, 0)) + 1) / 2.0 * 255.0  # post-processing: tranpose and scaling\n",
    "    else:  # if it is a numpy array, do nothing\n",
    "        image_numpy = input_image\n",
    "    return image_numpy.astype(imtype)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69228f96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(\n",
       "  (first_conv): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1))\n",
       "  (first_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (first_relu): ReLU(inplace=True)\n",
       "  (second_conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "  (second_norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (second_relu): ReLU(inplace=True)\n",
       "  (third_conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "  (third_norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (third_relu): ReLU(inplace=True)\n",
       "  (resnet_blocks): Sequential(\n",
       "    (0): ResnetBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (conv1_norm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (conv2_norm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    )\n",
       "    (1): ResnetBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (conv1_norm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (conv2_norm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    )\n",
       "    (2): ResnetBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (conv1_norm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (conv2_norm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    )\n",
       "    (3): ResnetBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (conv1_norm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (conv2_norm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    )\n",
       "    (4): ResnetBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (conv1_norm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (conv2_norm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    )\n",
       "    (5): ResnetBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (conv1_norm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (conv2_norm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    )\n",
       "    (6): ResnetBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (conv1_norm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (conv2_norm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    )\n",
       "    (7): ResnetBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (conv1_norm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (conv2_norm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    )\n",
       "    (8): ResnetBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (conv1_norm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (conv2_norm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    )\n",
       "  )\n",
       "  (content_upsample_conv_1): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "  (content_norm_upsample_1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (content_upsample_1_relu): ReLU(inplace=True)\n",
       "  (content_upsample_conv_2): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "  (content_norm_upsample_2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (content_upsample_2_relu): ReLU(inplace=True)\n",
       "  (content_upsample_conv_3): Conv2d(64, 27, kernel_size=(7, 7), stride=(1, 1))\n",
       "  (attention_upsample_conv_1): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "  (attention_norm_upsample_1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (attention_upsample_1_relu): ReLU(inplace=True)\n",
       "  (attention_upsample_conv_2): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "  (attention_norm_upsample_2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (attention_upsample_2_relu): ReLU(inplace=True)\n",
       "  (attention_upsample_conv_3): Conv2d(64, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (tanh): Tanh()\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform = transforms.ToTensor()\n",
    "\n",
    "my_model_checkpoint ='/kuacc/users/edincer16/Comp541_fall22/course_project/attentionGAN/model_results/baseline_weights/AttentionGAN_baseline_b4_212_net_G_A.pth'   \n",
    "my_model = AttentionGAN(input_dim=3,output_dim=3,n_epochs=5,norm_layer=nn.BatchNorm2d).cuda()\n",
    "my_model.netG_A.load_state_dict(torch.load(my_model_checkpoint))\n",
    "my_model.netG_A.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3ece7d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 120/120 [00:07<00:00, 15.79it/s]\n"
     ]
    }
   ],
   "source": [
    "input_path = '/kuacc/users/edincer16/Comp541_fall22/course_project/attentionGAN/horse2zebra/testA/*'\n",
    "output_path = '/kuacc/users/edincer16/Comp541_fall22/course_project/attentionGAN/model_results/baseline_outputs_for_fid_b4/'\n",
    "for img_path in tqdm(glob(input_path)):\n",
    "    img_name = img_path.split('/')[-1]\n",
    "    img_init = cv2.imread(img_path)\n",
    "    img = cv2.cvtColor(img_init, cv2.COLOR_BGR2RGB)\n",
    "    img = transform(img).unsqueeze(0)\n",
    "    my_generated_image, _, _, _, _, _, _, _, _, _, _, \\\n",
    "            _, _, _, _, _, _, _, _, _, _, \\\n",
    "            _, _, _, _, _, _, _, _, _  = my_model.netG_A(img.cuda())\n",
    "    gen_img = tensor2im(my_generated_image)\n",
    "    cv2.imwrite(output_path+img_name,\n",
    "                cv2.cvtColor(gen_img, cv2.COLOR_RGB2BGR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed606378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "100%|█████████████████████████████████████████████| 3/3 [00:01<00:00,  2.12it/s]\n",
      "FID:  170.67020030132116\n"
     ]
    }
   ],
   "source": [
    "#FID calculation\n",
    "!python -m pytorch_fid /kuacc/users/edincer16/Comp541_fall22/course_project/attentionGAN/horse2zebra/testA /kuacc/users/edincer16/Comp541_fall22/course_project/attentionGAN/model_results/baseline_outputs_for_fid_b4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b50c03b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
